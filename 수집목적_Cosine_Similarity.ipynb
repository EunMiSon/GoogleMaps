{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunMiSon/GoogleMaps/blob/master/%EC%88%98%EC%A7%91%EB%AA%A9%EC%A0%81_Cosine_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wY4Yp6JM-PmJ"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US0Tm3oH_gOP",
        "outputId": "ffd60c6c-e65b-4847-8bec-78d1a0cf2d1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7fUzxba_oej",
        "outputId": "425bde39-59b8-4f45-df40-c4638393e8f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWcBPnL_sym",
        "outputId": "c9b92205-9043-4de1-f9f7-e09e8292ac31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkzOE33E_wZP",
        "outputId": "05ae8c6a-e641-4e76-e2de-33ebc95e81ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "aFnhXmwp-Qta"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "7ddtD9Ws-S3J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Vb9w4Wg3-UK4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플1과 비교"
      ],
      "metadata": {
        "id": "_DEjM2VgpS-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample paragraphs\n",
        "paragraph1 = \"1. Purpose of collecting and using personal information A. Performance of contracts related to service provision and settlement of charges for service provision Content provision, purchase and payment, delivery of goods or billing destinations, financial transaction identity verification and financial services\"\n",
        "sample1 = \"1. Purpose of collecting and using personal information A. Performance of contracts related to service provision and settlement of charges for service provision Content provision, purchase and payment, delivery of goods or billing destinations, financial transaction identity verification and financial services B. Member management Complaints such as identification, personal identification, prevention of illegal and unauthorized use of defective members, confirmation of intention to sign up, age verification, confirmation of consent of legal representatives, complaints, etc 2. Personal information items collected: Name, date of birth, gender, login ID, password, home phone number, mobile phone number, e-mail, and information of legal representative for subscribers under the age of 14\""
      ],
      "metadata": {
        "id": "0VGN0gcK-eGF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "_O1IFkvW_atp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample1 = preprocess(sample1)"
      ],
      "metadata": {
        "id": "envLvtUO_dQQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample1])"
      ],
      "metadata": {
        "id": "NrytSmlm_06f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "AyL6Fkjp_3Yy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxVQo4yh_4i1",
        "outputId": "e386d939-afc0-4675-f693-614062223af6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.5412736398566319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플2와 비교"
      ],
      "metadata": {
        "id": "3ywogA9PAS9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample2 = \"The company processes the user's personal information for the following purposes. The personal information being processed will not be used for any purpose other than the following, and if the purpose of use is changed, necessary measures will be implemented, such as obtaining separate consent under Article 18 of the Personal Information Protection Act. Segmentation Processing Purpose Membership and membership management - Identification of members through identification based on the use of membership services - Limiting the number of duplicate memberships - Personal identification, sign-up intentions, age verification - Prevention of Unauthorized Use and Unauthorized Use of Defective Members - Preserving records for dispute settlement - Complaint handling, complaint handling, and customer counseling - Communicate disclaimers Engagement fulfillment and service delivery - Content Delivery - Purchases and Charges - Identification of the purchase of content - Postal delivery, delivery of goods, bills, etc - Customized entrance examination and provision of admission data\""
      ],
      "metadata": {
        "id": "1u8wz702_80f"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "QXSlLJa0AJfl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample2 = preprocess(sample2)"
      ],
      "metadata": {
        "id": "DMBQEFoXALSu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample2])"
      ],
      "metadata": {
        "id": "jOM7x3VUAFjc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "84g-HzgDAPpN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq2Q60cpAQtJ",
        "outputId": "0e75932f-2d1e-49da-b42a-70ae3cb2673f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.2488087719853289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플 3과 비교"
      ],
      "metadata": {
        "id": "FPZpmLZfcMR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample3 = \"Purpose of collection and use of personal information Personal information is used for identification and certification, maintenance and management of membership, prevention of fraudulent use of services, confirmation of consent of legal representatives when collecting personal information for children under the age of 14, handling complaints such as service use inquiries, and various notifications Personal information is used for the purpose of providing content and analyzing the user's environment and pattern for service improvement When using and participating in services such as participation in broadcasting and events, personal information is used to confirm users and deliver event winning products.\""
      ],
      "metadata": {
        "id": "mAm9QnvHcDhe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "NB0revVhcz4j"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample3 = preprocess(sample3)"
      ],
      "metadata": {
        "id": "-klM1SY2c16W"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample3])"
      ],
      "metadata": {
        "id": "xx9H655Sc8JB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "-hskRmUmc_HK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nK5s9fedA52",
        "outputId": "083b9b42-12e9-4bbc-b581-a4d9fbc2660c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.2384869409633438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플4와 비교"
      ],
      "metadata": {
        "id": "L-UVKqkqdc22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample4 = \"<Purpose of collecting and using personal information> The company uses the collected personal information for the following purposes. 1) Fee settlement for the provision of paid services for the performance of contracts related to the provision of services - Content provision, billing for the use of paid services, payment of purchases and charges, self-certification, delivery of goods or invoices, etc., and collection of charges 2) Member management - Identification, personal identification, prevention of illegal and unauthorized use of rogue members, duplicate subscription confirmation, subscription intention confirmation, age confirmation, legal representative consent when collecting personal information for children under 14 years of age 3) Use to deliver customized services - Personal information such as frequency of access and statistics on members' service use is used to recommend customized contents by providing customized services such as new service development and content recommendation, service maintenance and quality improvement, statistical characteristics, etc\""
      ],
      "metadata": {
        "id": "0dWyKbNMdgjO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "YDk9rVxTdlm_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample4 = preprocess(sample4)"
      ],
      "metadata": {
        "id": "77Ipg7uEdnbC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample4])"
      ],
      "metadata": {
        "id": "DSzPsxp_oxkc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "sEr09wQ4drIm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhT6bSgvdv2b",
        "outputId": "246b889c-4f39-423f-d595-8146aca8743b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.4683905311374248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플5와 비교"
      ],
      "metadata": {
        "id": "VYZRDeyHdwpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample5 = \"2. Purpose of collection and use of personal information and retention and use period The Nowon-gu website will retain and use minimum personal information to use the Nowon-gu website service only for the period of providing the service from the date of membership of the information subject. You can withdraw your consent to the collection, use, and provision of personal information through membership registration at any time. If a member withdrawal is requested, the purpose of collection/use is achieved, or the retention/use period is over, the personal information is destroyed in the event of a reason such as the abolition of the business. A. Name, IFIN - Purpose of collection and use: Use for self-certification procedures based on the use of the website (in the case of children's members, confirmation of consent by legal representative) - Retention and use period: Eye pins are not stored separately and are used only for identification purposes B. ID, password, name, gender, address, mobile phone, subscription authentication information, phone, email, job, notification application, items of interest - Purpose of collection and use: website service use and member management, prevention of unauthorized use of rogue members, civil petition and processing, notice delivery, post registration, data download, education course application results, electronic complaints, prize winning result guidance and product delivery - Retention and use period: Until membership withdrawal (However, newsletters and SMS are until application for termination) The data subject may refuse to consent to the purpose of collecting and using personal information, and if he/she refuses to consent, he/she will not be registered on the Nowon-gu website, and the service provided on the Nowon-gu website will not be available.\""
      ],
      "metadata": {
        "id": "ps3Xw-DjdzDV"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "Qs2Ue_4Fd5Rd"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample5 = preprocess(sample5)"
      ],
      "metadata": {
        "id": "l3ll1SSgd6z0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample5])"
      ],
      "metadata": {
        "id": "OB-7dPxHo7fe"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "qA3Ss6ETd-J1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGQD5hBwd_TL",
        "outputId": "7780ffc0-feb3-4e5a-84aa-762e55d50fde"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.15374132644531663\n"
          ]
        }
      ]
    }
  ]
}