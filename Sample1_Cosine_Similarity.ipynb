{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunMiSon/GoogleMaps/blob/master/Sample1_Cosine_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY4Yp6JM-PmJ"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US0Tm3oH_gOP",
        "outputId": "7be7ba77-2e06-4db6-96db-15d729cd62cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7fUzxba_oej",
        "outputId": "c2355638-64a9-4512-c766-ac3f9e778e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWcBPnL_sym",
        "outputId": "82958edd-a637-4cba-d0af-c46e7cbf1470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkzOE33E_wZP",
        "outputId": "6a892096-fe69-4534-f262-efd1465f8a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "aFnhXmwp-Qta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "7ddtD9Ws-S3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Vb9w4Wg3-UK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample paragraphs\n",
        "paragraph1 = \"2. Personal information items collected: Name, date of birth, gender, login ID, password, home phone number, mobile phone number, e-mail, and information of legal representative for subscribers under the age of 14\"\n",
        "paragraph2 = \"<Scope of items of personal information to be collected and The personal information collected by the company from members at the time of membership is as follows to provide services such as membership registration, counseling, and service application and to fulfill the contract. 1) Collect e-mail, name, date of birth, age, gender, profile picture, identification token, member number (only for members using SNS-linked or affiliated plan) and add legal representative information (name, date of birth, gender, duplicate registration information (DI, mobile phone) if the member's birth date is under the age of 14. Personal information collected from users during the service use process is as follows. 1) If a member wants to use a paid service, the company can collect the information necessary for payment as follows at the time of payment. - Payment method owner information (name), card information, mobile phone number, landline phone number, transaction ID issued for each payment, payment product code 2) The company may collect the following information if a member participates in an event or promotion. - Name, email address, mobile phone number, address, date of birth 3) Self-certification is conducted to restrict the use/purchase of contents and products according to age and to prevent fraudulent use of services, and name, date of birth, gender, domestic/foreigner status, mobile phone number, linked information (CI), and duplicate confirmation information (DI) can be collected. 4) When you refund cash, you can collect the depositor's name, account bank name, account number, and relationship document (if necessary). 5) When inquiring to the customer center, information such as email address, mobile phone number, name, date of birth, and payment information can be collected for accurate information. 6) For the purpose of providing customized recommendation services for members, behavioral information such as information on services that cannot identify users, access time, and frequency can be collected. The following information can be generated and collected during the service use process. 1) PC: PC MacAddress, PC specification information, browser information, and program version information used when using other services 2) Mobile phone (smartphone) & smart OS-based mobile device (Tablet PC, etc.) : Model name, unique number for each device (UDID, IME, etc.), OS information, mobile carrier, Google/Apple advertisement ID 3) Other information: service usage (stop) history, access log, cookies, access IP information\""
      ],
      "metadata": {
        "id": "0VGN0gcK-eGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "_O1IFkvW_atp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "paragraph2 = preprocess(paragraph2)"
      ],
      "metadata": {
        "id": "envLvtUO_dQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, paragraph2])"
      ],
      "metadata": {
        "id": "NrytSmlm_06f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "AyL6Fkjp_3Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxVQo4yh_4i1",
        "outputId": "ae8e7f79-f586-4252-b44a-c31dcd1e3a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.5316217605068895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "제목만 동의서고 내부 내용이 동의서가 아닌 경우"
      ],
      "metadata": {
        "id": "3ywogA9PAS9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph3 = \"<Purpose of collecting and using personal information> The company uses the collected personal information for the following purposes. 1) Fee settlement for the provision of paid services for the performance of contracts related to the provision of services - Content provision, billing for the use of paid services, payment of purchases and charges, self-certification, delivery of goods or invoices, etc., and collection of charges 2) Member management - Identification, personal identification, prevention of illegal and unauthorized use of rogue members, duplicate subscription confirmation, subscription intention confirmation, age confirmation, legal representative consent when collecting personal information for children under 14 years of age 3) Use to deliver customized services - Personal information such as frequency of access and statistics on members' service use is used to recommend customized contents by providing customized services such as new service development and content recommendation, service maintenance and quality improvement, statistical characteristics, etc\""
      ],
      "metadata": {
        "id": "1u8wz702_80f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "QXSlLJa0AJfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "paragraph3 = preprocess(paragraph3)"
      ],
      "metadata": {
        "id": "DMBQEFoXALSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, paragraph3])"
      ],
      "metadata": {
        "id": "jOM7x3VUAFjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "84g-HzgDAPpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq2Q60cpAQtJ",
        "outputId": "183515e2-9440-4715-9580-731374c6d263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.12959315560600768\n"
          ]
        }
      ]
    }
  ]
}